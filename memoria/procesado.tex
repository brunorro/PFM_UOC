\chapter{Entorno del proyecto}

\section{Análisis de requerimientos}
%Condiciones de iluminación, fondo, fotografías, etc.
En la realización del proyecto se tomarán las siguientes consideraciones:
\begin{itemize}
	\item{Las condiciones de iluminación serán constantes o similares.}
	\item{Cuanto menos variaciones tenga el fondo sobre el que se capturará la imagen del sujeto en cuestión también será mejor la robustez del sistema}
	\item{Se debe de tener en cuenta que el sistema reconoce fotografías de individuos puestas frente a la cámara como tales. Habría que mantener algún tipo de control sobre este problema.}
\end{itemize}
	
Asimismo, también tenemos que tener en cuenta los problemas inherentes a todo sistema electrónico. La previsión de ellos incrementa el coste de implantación, a costa de mejorar la disponibilidad en todos los aspectos:
\begin{itemize}
	\item{Fallos hardware (por desgaste). Para prevenir estos problemas, se debería replicar los componentes hardware que tengan posibilidad de fallo para dotar de alta disponibilidad a la infraestructura}
	\begin{itemize}
		\item{Duplicidad de fuentes de alimentación }
		\item{Replicación de discos duros: RAID1, RAID5, RAID10 o RAID01. }
		\item{Multiplicidad de accesos a red, lo cual no únicamente hace la infraestructura tolerante a fallos sino que puede agregar varias tarjetas de red (vía bonding o etherchannel/etherstack) }
		\item{En caso de almacenamiento compartido vía fibra óptica, replicación de HBA's \footnote{Host bus adapter, tarjetas que sirven para conectar las máquinas a la SAN.}. La replicación de switches de SAN también sería una alternativa a tener en cuenta, pero dispara el coste del sistema. }
	\end{itemize}

	\item{Cortes eléctricos}
	\begin{itemize}
		\item{Se hace necesaria la presencia de sistemas de alimentación ininterrumpida (SAIs) de capacidad calculada para la infraestructura.}
		\item{En caso de problemas más graves sería necesario tener un circuito alimentado por generadores o similares.}
	\end{itemize}

	\item{Infraestructura de comunicaciones: aquí los problemas no vienen dados sólo por el desgaste de los componentes, sino que además tenemos que tener en cuenta vulnerabilidades y ataques externos\footnote{A tener en cuenta el uso de rodenticidas. Los roedores tienen una afición especial por los cables UTP-5.}}
	\begin{itemize}
		\item{Contra los cortes en comunicaciones, se deberían tener replicadas las conexiones entre todos los switches utilizando STP (802.1W). Un ejemplo de redundancia se puede ver en la figura }
		\item{Uso de conexiones Gigabit o 10GbE }
		\item{Particionar la red de manera correcta en cuanto a VLAN's}
		\item{En caso de uso de redes inalámbricas, uso de encriptación WPA2 PSK o mejor. A ser posible, utilizar 802.1Q}
		\item{Tener bien separadas las máquinas de acceso externo en DMZs y utilizar VPN para accesos a la red interna. Comprobar la configuración de firewalls.}
	\end{itemize}

	\begin{figure}[h!]
        	\centering
		\input{diagramas/esquema_red.tex}
        	\caption{Esquema de red de alta disponibilidad.}
		\label{fig:network_diagram}
	\end{figure}

	\item{Ruido electromagnético}
		\begin{itemize}
			\item{Utilizar a ser posible cables STP o UTP-5 o superior para los cables de comunicaciones}
			\item{Comprobar distancias entre componentes dentro de los servidores}
			\item{Respetar las distancias y los estándares al respecto del montaje de centros de procesado de datos}
		\end{itemize}

	\item{Condiciones de humedad y temperatura}
		\begin{itemize}
			\item{Tener en cuenta la distribución de servidores en el centro de proceso de datos.}
			\item{Comprobar circuitos de aire acondicionado y conducciones de agua}
		\end{itemize}

	\item{Desastres naturales: incendios, inundaciones, terremotos, etc. }
		\begin{itemize}
			\item{Replicación de centros de procesos de datos (múltiples sites)}
			\item{Instalar un sistema anti-incendios de gas inergén en el/los centro de proceso de datos. En caso de incendio consume el oxígeno de la sala y minimiza las pérdidas.}
			\item{Establecer una política de copias de seguridad y mantenerlas a buen recaudo}
		\end{itemize}
\end{itemize}


\subsection{Hardware empleado}
El proyecto ha nacido como una solución de bajo coste y por tanto, los elementos que se han empleado se pueden encontrar fácilmente en el mercado doméstico a bajo coste. Los elementos hardware empleados han sido:
\begin{itemize}
	\item{Una webcam doméstica como dispositivo de captura}
	\item{Un ordenador personal.}
% Dar más detalles del PC
\end{itemize}

\subsection{Dispositivo de captura}

\begin{figure}[h!]
        \centering
	\includegraphics[height=4cm]{imagenes/camara_empleada.jpg}
	\includegraphics[height=4cm]{imagenes/camara_actual.jpg}
	\includegraphics[height=4cm]{imagenes/bayer_mosaic.png}
        \caption{Dispositivo de captura}
	\label{fig:webcam}
\end{figure}

En cuanto a la webcam, se eligió uno de los modelos más económicos que se encontraron. El fabricante comentaba que la cámara tenía 1.3 Megapíxeles, pero se debe tener en cuenta que los fabricantes indican el número de slots que tiene el sensor CMOS como megapíxels. Por cada 4 slots del sensor CMOS (agrupados en grupos de rojo, verde, verde, azul) tenemos un píxel real \footnote{Empleando la interpolación de Bayer, obtenemos un valor BGR de 3 bytes por cada píxel, que luego se convierte a RGB vía software para mostrar por pantalla.} con lo que la resolución real de la cámara es de unos 0,3 megapíxels. Por consiguiente, el tamaño del frame es de 640x480=307200 píxeles de 3 bytes cada uno (para cada uno de los colores indicados). 

En cuanto al resto de las características de la cámara, comentar que tiene incorporado un micrófono que no se ha empleado en ningún momento y que en teoría no ha afectado al desarrollo del proyecto. También hay que tener en cuenta que dicha cámara disponía de iluminación propia (4 leds) que, aunque bastante molesta, daban unas condiciones bastante homogéneas en cuanto a iluminación a costa de en muchos momentos sobreexponer la imagen. Se optó por hacer la mayoría de las pruebas tapando dichos leds con cinta aislante por las molestias que causaban. Actualmente el fabricante ha conservado el soporte de la cámara pero ha retirado los LEDs. También se modificó el soporte de la cámara, recortando y limando el soporte de sujección/pinza que tenía debido a que hacía más complicado el uso de ella. En la figura \ref{fig:webcam} se pueden ver, de izquierda a derecha, la cámara que se ha empleado para hacer las pruebas, el modelo que distribuye actualmente el vendedor (nótese la ausencia de LEDs) y el detalle de un sensor CCD de Webcam económica, donde cada cuadrado 2x2 (colores verde-azul-rojo-verde) corresponde a un píxel.

\subsection{Escenario}
\begin{figure}[h!]
        \centering
        \input{diagramas/pasos_sistema.tex}
        \caption{Procedimiento estándar de reconocimiento}
	\label{fig:pasos_captura}
\end{figure}

El procedimiento estándar de funcionamiento del sistema consta de los pasos mostrados en la figura \ref{fig:pasos_captura} y en los sucesivos apartados se dará una explicación más intensiva de cada uno de ellos.

\newpage

\section{Captura de imágenes}
La librería opencv dispone de la interfaz highgui que proporciona una capa de abstracción para que la obtención de imágenes desde una webcam sea un proceso sencillo. Dicha capa de abstracción permite capturar únicamente conociendo el Identificador de dispositivo que pertoca.
%Aplicación 

\subsection{Preprocesado de la imagen}
Para trabajar con la imagen, lo primero que se hace es un paso del formato BGR que captura la cámara a escala de grises. La imagen resultante pasa de tener 3 canales a un único canal, lo cual hace mucho más eficiente y rápido el procesado de esta (ocupa un tercio del tamaño original en memoria). Para la conversión de color a escala de grises, se emplea normalmente la siguiente fórmula:
\[
	G_{x,y}= 0.3 * R_{x,y} + 0.59 * G_{x,y} + 0.11 * B_{x,y}
\]
\begin{itemize}
	\item{$G_{x,y}$ es el valor en escala de grises del $(x,y)$ de la imagen }
	\item{$R, G, B$ son las componentes roja, verde y azul, respectivamente, de la imagen original}
\end{itemize}
Normalmente, $R_{x,y}, G_{x,y}, B_{x,y} \in \mathbb{N}_{0,255}$ y por tanto también $G_{x,y} \in \mathbb{N}_{0,255}$.

\begin{figure}[h!]
	\centering
	\includegraphics[height=6cm]{imagenes/lena_color_256.jpg}
	\includegraphics[height=6cm]{imagenes/lena_gray_256.jpg}
	\caption{Paso a escala de grises}
	\label{fig:grayscale_conversion}
\end{figure}

Asimismo se pueden aplicar con mayor facilidad modificaciones en el histograma. La principal de estas modificaciones aplicadas ha sido la normalización durante varios momentos de la obtención de características. Se procede a explicar aquí qué es la normalización, aunque realmente se aplica en pasos posteriores.

La normalización, ecualización o estiramiento lineal del histograma consiste en ampliar la gama cromática empleada en una imagen hasta ajustarla al número máximo de colores de que puede disponer esta imagen. Supongamos que tenemos una imagen en escala de grises ${X}$ y supongamos que $n_{i} \in \mathbb{N}_{0,255}$ es el número de ocurrencias de un nivel de grises $i$. Tenemos que la probabilidad de que haya un pixel con valor i en la imagen es:
\[
	p_{x}(i) = p(x=i)=\frac{n-{i}}{n}, 0 \leq i < L
\]
Definimos una función de distribución acumulativa ($fda$) que coincide con el histograma normal ecualizado y que se relaciona con $p_{x}$ de la siguiente manera:
\[
	fda_{x}(i) = \sum_{j=0}^{i}p_{x}(j)
\]
El estiramiento lineal consistirá en la creación de una nueva imagen $y$ en la que se interpolarán los valores de $fda$ a lo largo de todo el espectro de valores disponibles $\mathbb{N}_{0,255}$. Esto lo conseguimos multiplicando por una constante K cada valor para que la función de distribución de la nueva imagen sea:
\[
	fda_{y}(i)=iK
\]
La función de distribución acumulativa tiene nos permite hacer su inversa, definida como:
\[
	y = T(x) = fda_{x}(x)
\]
Teniendo en cuenta que $T(x)$ nos devolvería los valores en un intervalo $\left[0..1\right]$ debemos interpolar los valores contra el rango $\mathbb{N}_{0,255}$:
\[
	y' = y' (\max{x} - min {x}) + min{x}
\]

\begin{figure}[h!]
	\centering
	\includegraphics[height=6cm]{imagenes/lena_gray_256.jpg}
	\includegraphics[width=6cm, height=2cm]{imagenes/lena_gray_256_hist.png}\\
	\includegraphics[height=6cm]{imagenes/lena_gray_256_equalized.jpg}
	\includegraphics[width=6cm, height=2cm]{imagenes/lena_gray_256_equalized_hist.png}
	\caption{Normalización de histograma}
	\label{fig:normalize_hist}
\end{figure}

En la figura \ref{fig:normalize_hist} se muestran respectivamente una imagen en escala de grises junto a su histograma y en la siguiente línea, la misma imagen normalizada junto a su histograma, que podríamos considerar una representación gráfica de la $fda(x)$, donde cada punto en el eje X de la imagen se corresponde a un valor $i$ y en el eje Y vemos la aportación $p_{X}(i)$ que realiza a la imagen. se puede comprobar que:
\begin{itemize}
	\item{La imagen normalizada tiene un mayor rango de valores, con lo que aumenta el contraste entre las zonas oscuras y las zonas claras}
	\item{Como consecuencia de lo anterior, los bordes entre objetos quedan mejor demarcados.}
	\item{El histograma normalizado ocupa todo el rango $i$ de valores posibles. }
\end{itemize}

\newpage

\section{Determinación de la ubicación de la cara}
Para determinar las coordenadas en las que se encuentra la cara se utiliza el método mediante detección en cascada con identificadores de Haar comentado en la entrada \cite{ViolaJones} de la bibliografía. Este es un algoritmo que requiere de un entrenamiento de imágenes en las que se haya identificado la forma que se desea extraer. Este entrenamiento genera un clasificador en cascada\footnote{Un buen clasificador en cascada se obtiene a partir de las 7000 imágenes. El clasificador empleado en este proyecto era el que venía por defecto con la librería Opencv.} gracias al cual después la búsqueda de los objetos con formas similares al solicitado es muy rápida. 
%Casi toda la teoría, con dibujitos, formulitas y SOBRETODO referencia al Viola-Jones



\subsection{Escalado de la imagen}
Una vez se ha hallado la ubicación de la cara, se escala el tamaño de ésta para poder estandarizar parte de los procesos. El tamaño que se ha considerado más válido para trabajar es el de 128x128 píxeles, a 1 byte per píxel. En la gran mayoría de las imágenes de los juegos de prueba este tamaño es inferior al detectado, pero en caso de tener que ampliar la imagen se aplicaría un filtro bilinear por la relación calidad/tiempo de ampliación que suele tener.

Un filtro bilinear se encarga de escalar una imagen interpolando los cuatro píxeles más cercanos a la posición futura. En este caso, dado que estamos reduciendo la imagen, se puede considerar una adición de ruido despreciable. Dada la situación de la figura \ref{fig:interp_bilinear}, donde los píxeles los píxeles de la imagen original serían $P(1,1), P(1,2), P(2,1)$ y $P(2,2)$, $d$ la distancia en el eje $y$ del resultado interpolado al píxel original y $d'$ el análogo del anterior en el eje $x$, el valor de $P'(x,y)$ en la imagen interpolada se calcularía según la siguiente fórmula:

\[ P'(x,y) = P(1,1) (1-d) (1-d')+ P(1,2) d (1-d') + P(2,1) d (1-d') + P(2,2) d d'
\]

\begin{figure}[h!]
        \centering
        \input{diagramas/interp_bilinear.tex}
        \caption{Esquema de interpolación bilinear}
	\label{fig:interp_bilinear}
\end{figure}

Tras este paso, por consiguiente, habremos reducido el tamaño de trabajo a una matriz de 128x128 bytes. Escrito de manera formal, tendríamos que la imagen M se corresponde con la siguiente matriz:

\[ M=\left( \begin{array}{lcccccr} 
	m_{0,0} & m_{0,1} & m_{0,2} & \hdots & m_{0,125} & m_{0,126} & m_{0,127}\\
	m_{1,0} & m_{1,1} & m_{1,2} & \hdots & m_{1,125} & m_{1,126} & m_{1,127}\\
	\vdots & \vdots & \vdots & \ddots & \vdots & \vdots & \vdots \\
	m_{126,0} & m_{126,1} & m_{126,2} & \hdots & m_{126,125} & m_{126,126} & m_{126,127}\\
	m_{127,0} & m_{127,1} & m_{127,2} & \hdots & m_{127,125} & m_{127,126} & m_{127,127}
	\end{array} \right)
\]

%\[ \forall  m_{i,j} \in \mathbb{N} \and i_{i,j} \in \left[ 0..255 \right] \]
Donde $ \forall m_{i,j} \mid m_{i,j} \in \mathbb{N}_{\left[ 0,255 \right]} \wedge i,j \in \mathbb{N}_{\left[ 0,127 \right]} $
	

\subsection{Ubicación de los rasgos faciales}
Una vez disponemos de la cara ya escalada en BN, se llevan a cabo dos procesos:
\begin{itemize}
	\item{Localización de bordes aplicando el detector Sobel únicamente en orientación vertical}
	\item{Sobre el resultado previo aplicamos un algoritmo de ventana para hallar la ubicación de los ojos, la nariz y la boca.}
\end{itemize}

El detector de esquinas Sobel es muy conocido en el procesado de imagen y es relativamente rápido \footnote{Gracias a las mejoras del hardware actual (mayores anchos de banda de memoria, extensiones para el cálculo vectorial, cachés mayores, varios núcleos para paralelizar procesos...) la velocidad del procesado de imágenes ha mejorado exponencialmente. }. Informalmente, el Sobel halla los bordes de la imagen calculando una aproximación a la derivada de ésta, donde los máximos son el lugar donde hay un cambio en la imagen. En este proyecto utilizamos la convolución de la imagen con el siguiente kernel (informalmente, superponemos cada punto de la imagen con la siguiente matriz):

\[ \frac{\partial^{2}{M}}{\partial{y^{2}}} \approx S_{y}''= \left( \begin{array}{ccc} 1 & 2 & 1 \\ -2 & -4 & -2 \\ 1 & 2 & 1  \end{array} \right) \oplus M \]

Donde $\oplus$ es el operador de convolución. Concretamente, este es un kernel de apertura 3 (tamaño 3x3), para el cálculo de la segunda derivada en el eje Y. Nótese que en el proyecto únicamente se ha utilizado el kernel para calcular la derivada vertical, dado que con él hemos obtenido mejores resultados que calculando la derivada en ambos ejes. \footnote{Como comentario, el kernel con el que debería de convolucionarse la imagen para el cálculo de la segunda derivada horizontal sería el resultante de la trasposición del kernel aquí aplicado.}

\begin{figure}[h!]
	\centering
	\includegraphics[width=8cm]{zonas_busqueda_cara.png}
	\caption{Máscara aplicada sobre la imagen y tamaños de ventana}
	\label{fig:imagen_mascaras}
\end{figure}

Tras la detección de esquinas, procedemos a la búsqueda de los ojos, nariz y boca. Para ello, buscamos en el resultante de aplicar la máscara de la figura \ref{fig:imagen_mascaras} un algoritmo para buscar la ventana del tamaño indicado con suma de mayor valor. La búsqueda se realiza en el eje vertical de la imagen. Informalmente, buscamos la ventana de tamaño WxH (indicados en la imagen) cuyo valor de sumatorio sea el máximo. Formalmente, la región K es la resultante de la máscara que aparece en la imagen y se expresaría de la siguiente manera:
\[
 K = \left( 
	\begin{array}{lcccr} 
		k_{0,0} & k_{0,1} & \hdots & k_{0,j-2} & k_{0,j-1} \\
		\vdots & \vdots & \ddots & \vdots & \vdots \\
		k_{i-1,0} & k_{i-1,1} & \hdots & k_{i-1,j-2} & k_{i-1,j-1} \\
	\end{array} \right)
\]
Y que buscamos el valor de m según la siguiente ecuación. El sumatorio de la submatriz [(0,m), (W,m+H)] tendrá el valor máximo de la máscara indicada.
\[
   V = K\left[\left(0,m\right), \left(W,m+H\right) \right] \mid \forall n \sum_{i=0,j=n}^{i=W,j=n+H} K_{i,j} \leq \sum_{p=0,q=m}^{p=W,q=m+H} K_{p,q} 
\]
Este método se ha mostrado fiable, rápido y paralelizable (búsqueda de ambos ojos y nariz como tres hilos de ejecución diferentes, y tras el resultado de la detección de la nariz se puede realizar la búsqueda de la boca) aunque se ha reconocido casos en los que puede dar problemas. En la figura \ref{fig:imagenes_procesadas} podemos observar:
\begin{itemize}
	\item{A la izquierda la imagen original en color, con la región en la que se ha detectado la cara encuadrada.}
	\item{A la derecha, la primera imagen desde arriba es la cara detectada tras aplicar la conversión a escala de grises y el redimensionado bilinear.}
	\item{Bajo la anterior, está la imagen resultante de la aplicación del detector de esquinas Sobel de segundo orden sobre el eje Y.}
	\item{Por debajo de la anterior, tenemos encuadradas las máximas ventanas según los criterios previamente señalados.}
	\item{Finalmente, la imagen inferior de la derecha es el resultado de aplicar las ventanas halladas sobre la cara en escala de grises y redimensionada}
\end{itemize}
\begin{figure}[h!]
	\centering
	\includegraphics[width=12cm]{ejemplo_imagen_mujer.jpg}
	\caption{Pasos del procesado de la imagen}
	\label{fig:imagenes_procesadas}
\end{figure}
%si esto cuela y lo explico bien, doy volteretas

\newpage

\section{Extracción de características}
En estos momentos hemos determinado la región de interés a partir de la cual extraeremos la face signature. 
\subsection{Filtros de Gabor}
La transormada de Gabor es un caso especial de la transformada en tiempo discreto de Fourier. La función a transformar primero se convoluciona con una Gaussiana (se puede tratar como una ventana) y al resultado se le realiza una transformada de Fourier. En el caso monodimensional se definiría como:\\
\[
	G_{x}(t,f)=\int_{-\infty}^{+\infty}{e^{-\pi(\tau-t)^ 2e^{-2\pi jf \tau}}x(\tau)d\tau}
\]
	Debido a que la Gaussiana es una función definida entre $-\infty$ y $+\infty$ se debe asumir un comportamiento finito de ésta para que sea práctica y realizable. Si consideramos que la gaussiana :
\[
f(n) =  
\begin{cases}
	e^{-\pi a^2}\geq 10^{-5} & \parallel a \parallel \leq 1.9143 \\
	e^{-\pi a^2} < 10^{-5} & \parallel a \parallel > 1.9143 \\
\end{cases}
\]
Léase, que a partir de 1,9143 consideramos la contribución despreciable porque es inferior a $10^{-5}$. Haciendo esa aproximación nos queda la siguiente definición:
\[
	G_{x}(t,f)=\int_{-1.9143}^{+1.9143}{e^{-\pi(\tau-t)^ 2e^{-2\pi jf \tau}}x(\tau)d\tau}
\]
Dicha transformada tiene las siguientes propiedades: invertibilidad, linearidad, desplazamiento, modulación, propiedad de integración de potencia, propiedad de suma de energía, propiedad de reducción de propiedad, integrabilidad y recuperabilidad.\\
Un filtro de Gabor \cite{Lee96imagerepresentation} se podría considerar la aplicación de lo citado previamente al mundo de las señales discretas. Es un filtro lineal empleado en el procesado de imágenes para la detección de esquinas y características. Esta serie de filtros tienen un comportamiento frecuencial y de orientación similar al del córtex visual humano y se consideran particularmente apropiados para representar y discriminar texturas. En el dominio espacial (2 dimensiones) el filtrado de la señal se realiza convolucionándola con el/los correspondiente/s kernel de Gabor. Los kernels de Gabor son una Gaussiana modulada con un plano senoidal, y serían calculados con la siguiente fórmula:
\[
g(x,y;\lambda,\theta,\psi,\sigma,\gamma)=e^{-\frac{x'^2+\gamma^2y'^2}{2\sigma^2}}\cos\left(2\pi\frac{x'}{\lambda}+\psi\right)
\]

En esta expresión tenemos las siguientes variables:
\begin{itemize}
	\item{$\lambda$ es la longitud de onda del factor coseno}
	\item{$\phi$ es la orientación de la normal hacia las bandas paralelas de la función de Gabor\footnote{La función de Gabor ($g_{l,n}(x)=g(x-al)e^{2\pi ibnx}, -\infty < l,n < \infty, g\in L^2(R), \parallel g \parallel=1$ , donde $a$ y $b$ son constantes) fue desarrollada en 1946 por Dennis Gabor y se intentó aplicar para generar sonidos (sin éxito debido a que no tenía en cuenta el análisis frecuencial con respecto al tiempo de las señales de sonido en la vida real). No obstante, sentó precedente para la compresión de sonido y de vídeo. Se puede considerar una predecesora de las Wavelets. } }
	\item{$\psi$ es el desfase (orientación del kernel) }
	\item{$\sigma$ es la desviación estándar de la gaussiana convolucionada}
	\item{$\gamma$ es la ratio de aspecto espacial, que especifica la elipticidad de la función de Gabor con la que convolucionamos la gaussiana anterior.}
	\item{Los valores $ x'$ e $y'$ que son cambios de variable para los siguientes valores:} 
		\[ x' =x\cos\theta + y\sin\theta \] 
		\[y'=-x\sin\theta + y\cos\theta \] 
\end{itemize}

En la figura \ref{fig:gabor_example} tenemos un ejemplo del paso de una imagen sobre un banco de filtros de Gabor. La imagen original ocupa el primer tercio de la imagen y se ha elegido expresamente para comprobar la respuesta al filtro. El segundo tercio de la imagen contiene la representación de los kernel que se han empleado para convolucionar la imagen. Están agrupadas verticalmente por las orientaciones $\psi$ (0, 45, 90 y 135º respectivamente), mientras que horizontalmente están agrupadas por la desviación estándar de la gaussiana $\sigma$ (valores 16, 32, 64 y 128). En el tercio inferior se ve el resultado\footnote{Las imágenes han sido escaladas, se tiene que tener en cuenta que cada uno de los resultados tiene el mismo tamaño que la imagen original} de convolucionar la imagen original con cada uno de los kernels. Por ejemplo, cuando aplicamos el kernel con $\psi=0$ en el resultado no vemos la franja horizontal.

\begin{figure}[h!]
        \centering
	\includegraphics[height=21cm]{imagenes/Gabor.png}
        \caption{Aplicación de un banco de filtros de Gabor}
	\label{fig:gabor_example}
\end{figure}

\subsection{Obtención de la huella facial}
Para la obtención de la huella facial se han filtrado los rasgos (ojo derecho, ojo izquierdo, nariz y boca) por un filtro de Gabor. Dependiendo del uso que se le ha dado a la información obtenida tras el filtrado se han tenido en cuenta dos tipos de representación diferentes para la huella facial, las ventajas e inconvenientes de las cuales se detallarán posteriormente.

\begin{itemize}
	\item{Disposición lateral, en la que el resultado del filtrado por cada orientación se ha concatenado}
	\item{Superposición, en la que se ha hecho una suma ponderada de todos los resultados del filtrado por cada orientación}
\end{itemize}

Asímismo, también se ha umbralizado y aplicado el suavizado sobre las huellas faciales para comprobar si estadísticamente existía alguna mejora. También se detalla posteriormente.

\subsubsection{Disposición lateral de filtrados}
La disposición lateral de es una representación en la que se concatena en el eje X de la imagen cada uno de los resultados de convolucionar la imagen por cada uno de los filtros que forman parte del banco empleado. Las ventajas de este método de almacenamiento de la huella facial son las siguientes:
\begin{itemize}
	\item{Mejor respuesta estadística: da mejores resultados cuando se calcula la distancia entre dos face signatures}
	\item{Mejor visibilidad de cada una de las componentes empleadas}
\end{itemize}
A su vez, también tiene los siguientes inconvenientes:
\begin{itemize}
	\item{Tamaño de signature dependiente del tamaño del banco de filtros}
	\item{Mayor ocupación de memoria y de espacio en la base de datos}
	\item{Tiempos superiores para el cálculo de distancia entre individuos}
	\item{En caso de cambio del banco de filtros, se deben recrear todas las huellas faciales, toda la base de datos, etc.}
\end{itemize}
En la figura \ref{fig:filter_concat} podemos observar el funcionamiento de la concatenación de filtros. En la primera línea tenemos los rasgos obtenidos (ojo derecho, ojo izquierdo, nariz y boca). En las filas subsiguientes están el resultado de concatenar el filtrado de dichos rasgos en ese orden. Cada grupo de tres tiene las orientaciones $\psi = \alpha \in \left[0º,180º\right] | \alpha \mod{45º}=0$ ,  $\psi = \alpha \in \left[0º,180º\right] | \alpha \mod{20º}=0$,  $\psi = \alpha \in \left[0º,180º\right] | \alpha \mod{10º}=0$ respectivamente. Nótese que las imágenes están escaladas (todas tienen la misma altura en realidad), de tal manera que en verdad a cada orientación que se añade se estaría incrementando el tamaño de la huella facial.

\begin{figure}[h!]
	\centering
	\includegraphics[width=15cm]{imagenes/M2_concat.jpg}\\

	\includegraphics[width=15cm]{imagenes/M2_concat_od_45deg.png}
	\includegraphics[width=15cm]{imagenes/M2_concat_oi_45deg.png}
	\includegraphics[width=15cm]{imagenes/M2_concat_nariz_45deg.png}
	\includegraphics[width=15cm]{imagenes/M2_concat_boca_45deg.png}\\

	\includegraphics[width=15cm]{imagenes/M2_concat_od_20deg.png}
	\includegraphics[width=15cm]{imagenes/M2_concat_oi_20deg.png}
	\includegraphics[width=15cm]{imagenes/M2_concat_nariz_20deg.png}
	\includegraphics[width=15cm]{imagenes/M2_concat_boca_20deg.png}\\

	\includegraphics[width=15cm]{imagenes/M2_concat_od_10deg.png}
	\includegraphics[width=15cm]{imagenes/M2_concat_oi_10deg.png}
	\includegraphics[width=15cm]{imagenes/M2_concat_nariz_10deg.png}
	\includegraphics[width=15cm]{imagenes/M2_concat_boca_10deg.png}
	\caption{Concatenación de filtrados}
	\label{fig:filter_concat}
\end{figure}

\subsubsection{Superposición de filtrados}
En la superposición de filtrados, ponderamos el resultado de filtrar la imagen por cada uno de los filtros que forman parte del banco y los superponemos todos ellos sobre la imagen. Las ventajas principales de este método de almacenamiento de la huella facial son las siguientes:
\begin{itemize}
	\item{Tamaño de la signature constante, y de hecho es el mismo que el de la imagen filtrada}
	\item{Mejores tiempos en cálculo de distancias}
	\item{Menor espacio en memoria y en base de datos}
	\item{En caso de cambio del banco de filtros, puede mantenerse la misma huella facial, aunque las distancias puedan variar significativamente}
\end{itemize}
A su vez, también tiene los siguientes inconvenientes:
\begin{itemize}
	\item{Peor rendimiento estadístico: da más errores en los cálculos de distancia}
	\item{Se pierde la capacidad de determinar qué filtro es el que aporta más información a la face signature}
\end{itemize}

En la figura \ref{fig:filter_superp} podemos observar el funcionamiento de la superposición de filtros. En la primera línea tenemos los rasgos obtenidos (ojo derecho, ojo izquierdo, nariz y boca). En las filas subsiguientes están el resultado de superponer el filtrado de dichos rasgos en ese orden, y con $\psi = \alpha \in \left[0º,180º\right] | \alpha \mod{45º}=0$ ,  $\psi = \alpha \in \left[0º,180º\right] | \alpha \mod{20º}=0$,  $\psi = \alpha \in \left[0º,180º\right] | \alpha \mod{10º}=0$ respectivamente.

\begin{figure}[h!]
	\centering
	\includegraphics[width=15cm]{imagenes/M2_concat.jpg}\\
	\includegraphics[width=3.6cm]{imagenes/M2_superpos_od_45deg.png}
	\includegraphics[width=3.6cm]{imagenes/M2_superpos_od_20deg.png}
	\includegraphics[width=3.6cm]{imagenes/M2_superpos_od_10deg.png}\\
	\includegraphics[width=3.6cm]{imagenes/M2_superpos_oi_45deg.png}
	\includegraphics[width=3.6cm]{imagenes/M2_superpos_oi_20deg.png}
	\includegraphics[width=3.6cm]{imagenes/M2_superpos_oi_10deg.png}\\
	\includegraphics[width=3.2cm]{imagenes/M2_superpos_nariz_45deg.png}
	\includegraphics[width=3.2cm]{imagenes/M2_superpos_nariz_20deg.png}
	\includegraphics[width=3.2cm]{imagenes/M2_superpos_nariz_10deg.png}\\
	\includegraphics[width=4cm]{imagenes/M2_superpos_boca_45deg.png}
	\includegraphics[width=4cm]{imagenes/M2_superpos_boca_20deg.png}
	\includegraphics[width=4cm]{imagenes/M2_superpos_boca_10deg.png}
	\caption{Superposición de filtrados}
	\label{fig:filter_superp}
\end{figure}


\subsubsection{Umbralización}
La umbralización de una imagen $I$ es un proceso en el que a los píxeles que superan (o están por debajo) de un valor determinado $T$ se les aplica una modificación de valor. Durante la ejecución del proyecto se han probado tres tipos de umbralización: binarización, truncado y reducción a cero\footnote{La librería OpenCV permitía varios tipos más de umbralización.}.
\begin{itemize}
	\item{En la binarización a la imagen y al valor umbral (\textit{threshold} en inglés, de ahí el uso de T), se le añade como parámetro el valor M (de máximo) que es el que tomarán los píxeles que sobrepasen el umbral. Se puede ver un ejemplo en la imagen \ref{fig:thr_binarization}, en el que el valor máximo $M=255$ y el valor umbral es $T=(0,30,60,90)$ en la primera fila y $T=(120,150,180,210)$ en la segunda. Formalmente la binarización se define como:}
	\[
		thr(I,T,M) = \begin{cases}
				0, & \text{si $I_{x,y} < T$}\\
				M, & \text{si $I_{x,y} \geq T$}
			\end{cases}
	\]

	\begin{figure}[h!]
		\centering
		\includegraphics[width=8cm]{imagenes/umbral_binarizada.png}\\
		\caption{Huella facial binarizada}
		\label{fig:thr_binarization}
	\end{figure}

	\item{El truncado necesita como parámetros la imagen y el valor umbral, y formalmente se definiría de la siguiente manera:}
	\[
		thr(I,T) = \begin{cases}
				0, & \text{si $I_{x,y} < T$}\\
				T & \text{si $I_{x,y} \geq T$}
			\end{cases}
	\]
	\begin{figure}[h!]
		\centering
		\includegraphics[width=8cm]{imagenes/umbral_truncada.png}\\
		\caption{Huella facial truncada}
		\label{fig:thr_truncate}
	\end{figure}

	\item{La reducción a cero necesita como parámetros la imagen y el valor umbral, y formalmente se definiría de la siguiente manera:}
	\[
		thr(I,T) = \begin{cases}
				0, & \text{si $I_{x,y} < T$}\\
				I_{x,y}, & \text{si $I_{x,y} \geq T$}
			\end{cases}
	\]

	\begin{figure}[h!]
		\centering
		\includegraphics[width=8cm]{imagenes/umbral_tozero.png}\\
		\caption{Huella facial con nivel a 0}
		\label{fig:thr_tozero}
	\end{figure}

\end{itemize}

\subsubsection{Suavizado}
El suavizado de una imagen (\textit{smooth} en inglés) consiste en reducir las diferencias entre píxeles colindantes, con lo que el resultado de la operación vendría a ser la imagen desenfocada o 'difuminada'. Existen varios métodos para suavizar una imagen, pero el más común es convolucionar con una gaussiana.

	\begin{figure}[h!]
		\centering
		\includegraphics[width=8cm]{imagenes/suavizado.png}\\
		\caption{Suavizado de imagen}
		\label{fig:smooth}
	\end{figure}



\subsection{Comparación entre huellas faciales}

Se han probado diversas medidas de disimilitud entre las huellas faciales extraídas:
\begin{itemize}
	\item{Distancia Euclídea ponderada (distancia euclídea entre huellas faciales ponderada)}
	\item{Distancia And/Or (cociente entre el sumatorio de la and y la or de las huellas faciales)}
	\item{Distancia Xor/Or (cociente entre la or exclusiva y la or lógica de las huellas faciales)}
\end{itemize}
Para facilitar la búsqueda de diferencias, se han probado todas las medidas de similitud umbralizando bajo diferentes valores las imágenes.
Las medidas de disimilitud se detallan a continuación.
\subsubsection{Distancia euclídea ponderada}
La distancia euclídea es una 'clásica' para la comparación entre dos señales o similares. Aquí se ha ponderado, empleando la siguiente expresión:
\[
D_{euc}(m,n)=\frac{\sum_{i,j=0}^{X,Y}{\sqrt{(m_{i,j}-n_{i,j})^2}}}{XY}
\]
Donde $m$ y $n$ son las imágenes y $X$ e $Y$ son el ancho y el alto de éstas. La ponderación viene dada tras la división entre el tamaño de la imagen (el denominador de la fracción). Aunque en vistas a la eficiencia, si tenemos en cuenta que la elevación al cuadrado y la raíz cuadrada se hacen únicamente para evitar que valores positivos y negativos modifiquen el resultado tenemos la siguiente expresión, que ha sido la empleada:
\[
D_{euc}(m,n)=\frac{\sum_{i,j=0}^{X,Y}{\parallel m_{i,j}-n_{i,j}\parallel}}{XY}
\]
donde $\parallel$ es el valor absoluto de la resta 'píxel a píxel' entre imágenes. Esta medida tiene las siguientes características:
\begin{itemize}
	\item{$D_{euc}\in\mathbb{R}_{0,255}$ (el valor de $D_{euc}$ es un natural en el intervalo $\left[0,255\right]$)} 
	\item{Es conmutativa por definición ($D_{euc}(i,j)=D_{euc}(j,i)$)}
	\item{Es una medida de disimilitud, es decir, que $D_{euc}(i,j) > D_{euc} (i,k)$ significaría que $i$ es más similar a $k$ que $j$}
	\item{Esta medida se ha mostrado con una validez muy baja debido a una muy alta variabilidad.}
\end{itemize}

Si por ejemplo disponemos de las siguientes matrices simulando imágenes de 1 byte per píxel:
\[ M=\left( \begin{array}{lcr}
	255 & 127 & 255 \\
	0 & 0 & 255 \\
	255 & 0 & 0 
\end{array} \right), N=\left( \begin{array}{lcr}
	255 & 255 & 0 \\
	0 & 255 & 255 \\
	255 & 0 & 127 
\end{array} \right) 
\]
Entonces tendríamos que 
\[D_{euc}(M,N) = \frac
	{\sum_{i,j=0}^{3,3}\left( 
		\begin{array}{lcr}
			0 & 128 & 255\\ 0 & 255 & 0 \\ 0 & 0 & 127 
		\end{array} 
	\right)}
	{9} = 85
\]
La distancia euclídea como tal entre una imagen y otra es 85. Podríamos pasarla a un intervalo $p \in \mathbb{R}_{0..1}$ mediante una interpolación sencilla:
\[
	p = \frac{D_{euc}}{255}
\]
y en este caso la distancia entre matrices sería $D_{euc}=\frac{85}{255}\approx0,333$, lo cual nos indicaría que la similitud entre ambas imágenes es aproximadamente del 33,3\%. Por otro lado, trabajar con números naturales por norma general suele ser menos costoso para la CPU, así que se ha trasladado el resultado de $\mathbb{R}_{0,255}$ a $\mathbb{N}_{0,255}$.

\subsubsection{Distancia And/Or}
La distancia And/Or se ha calculado de la siguiente manera:
\[
D_{and}(m,n)=\frac{ \sum_{x,y=0}^{X,Y}(m_{x,y} \wedge n_{x,y}) }{ \sum_{x,y=0}^{X,Y}(m_{x,y} \vee n_{x,y}) }
\]
El operador $\wedge$ representa la and (y lógica) bit a bit entre píxel y píxel de la imagen, y el operador $\vee$ la or (o lógica) entre píxeles. 
\begin{itemize}
	\item{$D_{and}\in\mathbb{R}_{\left[0,1\right]}$ (el valor de $D_{and}$ es un real en el intervalo $\left[0,1\right]$)} 
	\item{Es conmutativa por definición ($D_{and}(i,j)=D_{and}(j,i)$)}
	\item{Es una medida de similitud, es decir, que $D_{and}(i,j) > D_{and} (i,k)$ significaría que $i$ es más similar a $j$ que $k$}
	\item{Esta medida se ha mostrado con una validez muy baja debido a una muy alta variabilidad.}
\end{itemize}

Si disponemos de las matrices del caso anterior:
\[ M=\left( \begin{array}{lcr}
	255 & 127 & 255 \\
	0 & 0 & 255 \\
	255 & 0 & 0 
\end{array} \right), N=\left( \begin{array}{lcr}
	255 & 255 & 0 \\
	0 & 255 & 255 \\
	255 & 0 & 127 
\end{array} \right) 
\]

Para calcular la $D_{and}(M.N)$ necesitaríamos calcular inicialmente $M \wedge N$ y $M \vee N$
\[ (M \wedge N)=\left( \begin{array}{lcr}
	255 & 127 & 0 \\
	0 & 0 & 255 \\
	255 & 0 & 0 
\end{array} \right), (M \vee N)=\left( \begin{array}{lcr}
	255 & 255 & 255 \\
	0 & 255 & 255 \\
	255 & 0 & 127 
\end{array} \right) 
\]

El cálculo de la distancia se haría a partir de ambos sumatorios:
\[D_{and}(M,N) = \frac 
	{\sum_{i,j=0}^{3,3} M \wedge N} 
	{\sum_{i,j=0}^{3,3} M \vee N} = \frac {892}{1657} = 0,538322269 
\]
Si hacemos la aproximación $ 0,538322269 \approx 0,54 $ tenemos que ambas matrices tienen un índice de similitud del 54\%.

\subsubsection{Distancia Xor/Or}
La distancia Xor/Or se ha calculado de la siguiente manera:
\[
D_{xor}(m,n)=\frac{ \sum_{x,y=0}^{X,Y}(m_{x,y} \oplus n_{x,y}) }{ \sum_{x,y=0}^{X,Y}(m_{x,y} \vee n_{x,y}) }
\]
En este caso el operador $\oplus$ representa la or exclusiva (XOR) entre píxel y píxel de la imagen, y el operador $\vee$, de igual manera que antes, la OR entre ambos.
\begin{itemize}
	\item{$D_{xor}\in\mathbb{R}_{\left[0,1\right]}$ (el valor de $D_{xor}$ es un real en el intervalo $\left[0,1\right]$)} 
	\item{Es conmutativa por definición ($D_{xor}(i,j)=D_{xor}(j,i)$)}
	\item{Es una medida de disimilitud, es decir, que $D_{xor}(i,j) > D_{xor} (i,k)$ significaría que $i$ es más similar a $k$ que $j$}
	\item{Esta medida se ha mostrado con una validez muy baja debido a una muy alta variabilidad.}

\end{itemize}
Utilizando las matrices representando imágenes del caso anterior:
\[ M=\left( \begin{array}{lcr}
	255 & 127 & 255 \\
	0 & 0 & 255 \\
	255 & 0 & 0 
\end{array} \right), N=\left( \begin{array}{lcr}
	255 & 255 & 0 \\
	0 & 255 & 255 \\
	255 & 0 & 127 
\end{array} \right) 
\]

Para calcular la $D_{xor}(M.N)$ utilizaremos $M \oplus N$ y $M \vee N$ (que será la misma que en $D_{and}$)
\[ (M \oplus N)=\left( \begin{array}{lcr}
	0 & 128 & 255 \\
	0 & 255 & 0 \\
	0 & 0 & 127 
\end{array} \right), (M \vee N)=\left( \begin{array}{lcr}
	255 & 255 & 255 \\
	0 & 255 & 255 \\
	255 & 0 & 127 
\end{array} \right) 
\]

El cálculo de la distancia se haría a partir de ambos sumatorios:
\[D_{xor}(M,N) = \frac 
	{\sum_{i,j=0}^{3,3} M \oplus N} 
	{\sum_{i,j=0}^{3,3} M \vee N} = \frac {765}{1657} = 0,461677731
\]
Si hacemos la aproximación $ 0,461677731 \approx 0,46 $ tenemos que ambas matrices tienen un índice de disimilitud del 46\%.


\subsection{Identificación}

